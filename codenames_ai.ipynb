{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CodeNamesAI Walkthrough\n",
    "\n",
    "Table of Contents:\n",
    "* [Downloading Embed Modules](#downloading_embed_modules)\n",
    "* [Saving Vocabulary Embeddings](#saving_vocabulary_embeddings)\n",
    "* [Playing As Operative](#playing_as_operative)\n",
    "* [Playing As SpyMaster](#playing_as_spymaster)\n",
    "* [Thoughts And Next Steps](#thoughts_and_next_steps)\n",
    "\n",
    "Feel free to skip around, each section is completely self-contained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"downloading_embed_modules\"></a>\n",
    "# Downloading Embed Modules\n",
    "\n",
    "The first step is to download a word/sentence embedder from TFHub. These can be very large models {oddly enough, the 'small' version of the Universal Sentence Encoder {1GB} seems to be larger than the 'large' version {800MB}). And they can take a long time to load (closer to hours than minutes) the first time.  Fortunately, once they load once, they are cached on your system, and will load quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "# module_url = \"https://tfhub.dev/google/Wiki-words-250-with-normalization/1\"\n",
    "# module_url = \"https://tfhub.dev/google/Wiki-words-500-with-normalization/1\"\n",
    "\n",
    "# Import the TF Hub module\n",
    "embed_module = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"saving_vocabulary_embeddings\"></a>\n",
    "#  Saving Vocabulary Embeddings\n",
    "\n",
    "First, word embeddings for the vocabulary needs to be made and saved in a lookup table for later reference. This is need for the SpyMasterAI, and needs to include all words that will make up the vocabulary of 'clue' candidates.\n",
    "\n",
    "Different embeddings need to be saved for each seperate embed_module you intend to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T06:43:49.040939Z",
     "start_time": "2018-06-20T06:43:44.683997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micah\\Anaconda3\\envs\\codenames\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from embedder import Embedder\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "# Reduce logging output (otherwise flooded with INFO messages when loading module)\n",
    "hub.tf.logging.set_verbosity(hub.tf.logging.ERROR)\n",
    "embed_module = hub.Module(module_url)\n",
    "vocab1 = 'vocabulary/original.txt'\n",
    "vocab2 = 'vocabulary/words.txt'\n",
    "embeddings_path = 'embeddings/USE_embeddings.json'\n",
    "\n",
    "\n",
    "\n",
    "embedder = Embedder(embed_module, embeddings_path, vocab1)\n",
    "# Let's see if there was any vocab stored in embeddings_path already\n",
    "embedder.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-20T05:36:29.611Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting embeddings for all words in the vocab1 vocab list. This could take awhile.\n",
    "embedder.add_embeddings_from_txt(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding on the embeddings from vocab2 as well, and saving lookup table\n",
    "embedder.new_vocabulary_txt = vocab2\n",
    "embedder.add_embeddings_from_txt(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manually add words to the embeddings vocabulary, and choose whether or not to write the words to a vocab list.\n",
    "\n",
    "This could allow for specialized versions of the game where you are only allowed to provide hints from a specialized set of words (like say, disney princesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disney_princess_words = ['Ariel, Jasmine, Aurora, Rapunzel, Belle, Tiana, Cinderella, Merida, Snow, White, Pocahontas, Mulan']\n",
    "\n",
    "# You can update a pre-existing txt file, but we'll start a new one.\n",
    "disney_princess_txt = 'vocabulary/disney_princess.txt'\n",
    "embedder.new_vocabulary_txt = disney_princess_txt\n",
    "\n",
    "embedder.add_embeddings_from_list(disney_princess_words, add_to_txt=True, save=True)\n",
    "# this adds to the spymaster vocabulary that includes vocab1 and vocab2.\n",
    "# To create a specialized, small vocabulary, make a new Embedder object with a new embeddings_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"playing_as_operative\"></a>\n",
    "#  2) Playing As Operative\n",
    "\n",
    "As an operative, you can ask the OperativeAI to help you decide which tiles to guess based on a clue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T03:51:30.085238Z",
     "start_time": "2018-06-19T03:51:30.059227Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from operative import OperativeAI\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "embed_module = 'blah'\n",
    "\n",
    "game_words = ['Plane', 'Duck', 'Bat', 'Soldier', 'Pupil',\n",
    "              'India', 'Germany', 'Tower', 'Bark', 'Litter',\n",
    "              'March', 'Slug', 'Shot', 'Button', 'Microscope',\n",
    "              'Fish', 'Back', 'Circle', 'Canada', 'Cell',\n",
    "              'Slip', 'Triangle', 'Thief', 'Pie', 'Hawk']\n",
    "\n",
    "op_ai = OperativeAI(embed_module, game_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "On your first turn, let's say the spymaster gives the clue 'War' for 3 words \n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hint = 'War'\n",
    "op_ai.recommend_guess(hint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recommendations of 2 words\n",
    "op_ai.ngram_recommend_guess(hint, n_gram=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with 25 words, 3 will take awhile (that's a lot of permutations!)\n",
    "op_ai.ngram_recommend_guess(hint, n_gram=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "You guess 'Soldier', 'Germany', and 'Shot'. Then, the opposing team guesses 'Thief' and 'Tower' on their turn.\n",
    "\n",
    "Now, your SpyMaster offers the clue 'Science' for 2.\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove words that are no longer in the game\n",
    "op_ai.remove_words(['Soldier', 'Germany', 'Shot', 'Thief', 'Tower'])\n",
    "\n",
    "hint = 'Science'\n",
    "op_ai.recommend_guess(hint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it's that simple!\n",
    "op_ai.ngram_recommend_guess(hint, n_gram=2, k=10) # you can reduce the number of results shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"playing_as_spymaster\"></a>\n",
    "# Playing As SpyMaster\n",
    "Alright, here's where it get's interesting. You want to get help from the SpyMasterAI, which can help you find words that correlate with your teams words, but also try to make sure they don't correlate with the enemy words or the assassin word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T04:22:11.899432Z",
     "start_time": "2018-06-19T04:22:11.894431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [3, 4, 5], 'b': [6, 4, 6], 'c': [8, 8, 9], 't': [9, 8, 5]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spymaster import SpyMasterAI\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "module_url = ''\n",
    "embed_module = hub.Module(module_url)\n",
    "\n",
    "# location of saved embeddings using Embedder in step 1\n",
    "vocab_embeddings_path = 'blaah'\n",
    "\n",
    "red_words = ['Bat', 'Pupil', 'India', 'Tower', 'Litter', 'Slug', 'Button', 'Circle']\n",
    "blue_words = ['Bark', 'Shot', 'Microscope', 'Fish', 'Back', 'Canada', 'Cell', 'Triangle', 'Thief']\n",
    "nuetral_words = ['Plane', 'Soldier', 'Germany', 'March', 'Slip', 'Pie', 'Hawk']\n",
    "assasin_word = 'Duck'\n",
    "\n",
    "spy_ai = SpyMasterAI(embed_module, vocab_embeddings_path, red_words, blue_words, nuetral_words, assasin_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T04:21:43.131435Z",
     "start_time": "2018-06-19T04:21:43.126436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 't', 'c']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blue's turn\n",
    "spy_ai.recommend_hint('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SpyMasterAI will try to find the single word with the best semantic similarity to the entire list of team words, represented as a single sentence. In real life a SpyMaster would not generally do this, because trying to generalize so much weakens the semantic connections, making it harder for you team to guess correctly.\n",
    "\n",
    "A better approach is to feed the AI a smaller set of words which are more likely to have a strong semantic connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spy_ai.recommend_hint('blue', team_words=['Bat', 'Slug', 'Litter', 'Pupil'])\n",
    "#spy_ai.recommend_hint('blue', team_words=['Tower', 'Litter', 'Button', 'Circle'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is more helpful, you can also feed in the small set of words that you think are likely to have semantic relationships with your hint and chosen words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spy_ai.recommend_hint('blue', team_words=['Bat', 'Slug', 'Litter', 'Pupil'], problem_words = ['Bark', 'Duck', 'Fish', 'Cell'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you decide on your hint, and you're team makes their guesses, it's red's turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feed in list if there is more than one word to remove\n",
    "spy_ai.remove_blue(['Bat', 'Slug'])\n",
    "spy_ai.remove_neutral('Pie')\n",
    "# or alternatively:\n",
    "#spy_ai.remove(['Bat', 'Slug'], 'blue')\n",
    "#spy_ai.remove(['Bat', 'Slug'], 'neutral')\n",
    "\n",
    "spy_ai.recommend_hint('red', team_words=['Plane', 'Soldier', 'Germany', 'March'], problem_words = ['India', 'Shot', 'Canada', 'Litter', 'Tower', 'Thief'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"thoughts_and_next_steps\"></a>\n",
    "# Thoughts And Next Steps\n",
    "\n",
    "* Game class\n",
    "* Have AI vs AI game, Operative using Word2Vec and SpyMaster using USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# after Game is working, could have it play against itself (only really interesting if word2vec is used in one case and USE in another)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:codenames]",
   "language": "python",
   "name": "conda-env-codenames-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
